<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.5">
<title>tedata.search API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tedata.search</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tedata.search.search_TE"><code class="flex name class">
<span>class <span class="ident">search_TE</span></span>
<span>(</span><span>driver: <module 'selenium.webdriver' from '/Users/jamesbishop/Documents/miniconda3/envs/bm/lib/python3.11/site-packages/selenium/webdriver/__init__.py'> = None,<br>use_existing_driver: bool = False,<br>browser: Literal['chrome', 'firefox'] = 'firefox',<br>search_term: str = 'US ISM Services PMI',<br>headless: bool = True,<br>load_homepage: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class search_TE(object):
    &#34;&#34;&#34;Class for searching Trading Economics website and extracting search results.
    This class is designed to search the Trading Economics website for a given term and extract the search results.
    It can load the search page, enter a search term, and extract the URLs of the search results.

    **Init Parameters:**

    - driver (webdriver): A Selenium WebDriver object, can put in an active one or make a new one for a new URL.
    - use_existing_driver (bool): Whether to use an existing driver or make a new one.
    - browser (str): The browser to use for scraping, either &#39;chrome&#39; or &#39;firefox&#39;.
    - search_term (str): The term to search for on the website. Optional, can also provide it in the search_trading_economics method.
    - headless (bool): Whether to run the browser in headless mode (show no window).
    &#34;&#34;&#34;
    # Define browser type with allowed values
    BrowserType = Literal[&#34;chrome&#34;, &#34;firefox&#34;]
    
    def __init__(self, driver: webdriver = None, 
                 use_existing_driver: bool = False,
                 browser: BrowserType = &#34;firefox&#34;, 
                 search_term: str = &#34;US ISM Services PMI&#34;,
                 headless: bool = True,
                 load_homepage: bool = True):
        
        self.browser = browser
        self.headless = headless

        logger.debug(f&#34;Initializing search object with browser: {browser}, headless: {headless}, use_existing_driver: {use_existing_driver}&#34;)
        active = utils.find_active_drivers() 
        if len(active) &lt;= 1:
            use_existing_driver = False

        if driver is None and not use_existing_driver:
            if browser == &#34;chrome&#34;:
                print(&#34;Chrome browser not supported yet. Please use Firefox.&#34;)
                # self.driver = utils.setup_chrome_driver(headless = headless)
            elif browser == &#34;firefox&#34;:
                options = webdriver.FirefoxOptions()
                if headless:
                    options.add_argument(&#39;--headless&#39;)
                self.driver = utils.TimestampedFirefox(options=options)
            else:
                logger.debug(f&#34;Error on driver initialization: Unsupported browser: {browser}&#34;)
                raise ValueError(&#34;Unsupported browser! Use &#39;chrome&#39; or &#39;firefox&#39;.&#34;)
            logger.debug(f&#34;New webdriver object initialized: {self.driver}&#34;)
            logger.info(f&#34;New webdriver object initialized: {self.driver}&#34;)
        elif use_existing_driver:   ## May want to change this later to make sure a scraper doesn&#39;t steal the driver from a search object.
            self.driver = active[-1][0]
            logger.debug(f&#34;Using existing webdriver object: {self.driver}&#34;)
            logger.info(f&#34;Using existing webdriver object: {self.driver}&#34;)
        else:
            self.driver = driver
            logger.debug(f&#34;Using provided webdriver object: {self.driver}&#34;)
            logger.info(f&#34;Using provided webdriver object: {self.driver}&#34;)
        
        self.wait = WebDriverWait(self.driver, timeout=10)
        logger.debug(f&#34;Driver of search_TE object initialized: {self.driver}&#34;)
        self.search_term = search_term
        if load_homepage:
            self.home_page()

    def home_page(self, timeout: int = 30):
        &#34;&#34;&#34;Load the Trading Economics home page.
        :Parameters:
        - timeout (int): The maximum time to wait for the page to load, in seconds.

        &#34;&#34;&#34;
        # Load page
        try:
            logger.info(&#34;Loading home page at https://tradingeconomics.com/ ...&#34;)
            self.driver.get(&#34;https://tradingeconomics.com/&#34;)

            # Wait for 5 seconds
            time.sleep(5)
            # Check if search box exists
            search_box = self.driver.find_elements(By.ID, &#34;thisIstheSearchBoxIdTag&#34;)
            if search_box:
                logger.info(&#34;Home page at https://tradingeconomics.com loaded successfully! Search box element found.&#34;)
            else:
                logger.info(&#34;Home page at https://tradingeconomics.com loaded successfully! Search box element not found though.&#34;)
            
        except Exception as e:
            logger.info(f&#34;Error occurred, check internet connection. Error details: {str(e)}&#34;)
            logger.debug(f&#34;Error occurred, check internet connection. Error details: {str(e)}&#34;)

    def search_trading_economics(self, search_term: str = None):
        &#34;&#34;&#34;Search Trading Economics website for a given term and extract URLs of search results.
        This method will search the Trading Economics website for a given term and extract the URLs of the search results.
        It will enter the search term in the search box, submit the search, and extract the URLs of the search results.
        Results are assigned to the &#39;results&#39; attribute as a list of URLs and as result_table attribute as a pandas df.

        **Parameters:**

        - search_term (str): The term to search for on the website.
        &#34;&#34;&#34;

        self.current_page = self.driver.current_url
        if self.current_page != &#34;https://tradingeconomics.com/&#34;:
            self.home_page()
            time.sleep(2)
 
        if search_term is None:
            search_term = self.search_term
        else:
            self.search_term = search_term
        logger.debug(f&#34;Searching Trading Economics for: {self.search_term}&#34;)
        
        try:
        # Wait for search box - using the ID from the HTML
            search_box = WebDriverWait(self.driver, 30).until(
                EC.presence_of_element_located((By.ID, &#34;thisIstheSearchBoxIdTag&#34;)))
   
            # Click search box
            logger.info(&#34;Clicking search box...&#34;)
            search_box.click()
            
            # Enter search term
            logger.info(f&#34;Entering search term: {search_term}&#34;)
            search_box.send_keys(search_term)
            time.sleep(1)  # Small delay to let suggestions appear
            
            # Press Enter
            logger.info(&#34;Submitting search...&#34;)
            search_box.send_keys(Keys.RETURN)
            
            # Wait a moment to see results
            time.sleep(3)

            self.results = self.extract_search_results(self.driver.page_source)
            self.results_table()
            logger.debug(f&#34;Search for {self.search_term} completed successfully.&#34;)
        
        except Exception as e:
            logger.info(f&#34;Error occurred: {str(e)}&#34;)
            logger.debug(f&#34;Error on search occurred: {str(e)}&#34;)
            return None
        
    def extract_search_results(self, html_content):
        &#34;&#34;&#34;Extract URLs from search results page&#34;&#34;&#34;
        
        soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
        
        # Find all list items in search results
        results = soup.find_all(&#39;li&#39;, class_=&#39;list-group-item&#39;)
        
        urls = []
        for result in results:
            # Find the main link in each result item
            link = result.find(&#39;a&#39;, href=True)
            if link and link[&#39;href&#39;].startswith(&#39;/&#39;):
                full_url = f&#34;https://tradingeconomics.com{link[&#39;href&#39;]}&#34;
                urls.append(full_url)
        
        return urls
    
    def results_table(self):
        &#34;&#34;&#34;Create a DataFrame from the search results&#34;&#34;&#34;

        if hasattr(self, &#34;results&#34;):
            metrics = []
            countries = []
            for result in self.results:
                metrics.append(result.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;))
                countries.append(result.split(&#34;/&#34;)[-2].replace(&#34;-&#34;, &#34; &#34;))
            df = pd.DataFrame({&#39;country&#39;: countries, &#39;metric&#39;: metrics, &#34;url&#34;: self.results})
            df.index.rename(&#39;result&#39;, inplace=True)
            self.result_table = df
        else:
            print(&#34;No search results found.&#34;)
            return None
        
    def get_data(self, result_num: int = 0):
        &#34;&#34;&#34;Scrape data for a given search result number.
        This method will scrape data for a given search result number from the search results table.
        It will extract the URL for the result and scrape the data from the chart at that URL.
        The scraped data is assigned to the &#39;scraped_data&#39; attribute as a TE_scraper object.
        This will use the TE_Scraper class and methods to scrape the data from the Trading Economics website.
        
        **Parameters:**
        - result_num (int): The index of the search result in your result table to scrape the data for.

        **Returns:**
        - scraped_data (TE_Scraper): The scraped data object. The data can be accessed from the &#39;series&#39; attribute of the TE_SCraper object
        that is returned. This object is also saved as the &#34;scraped_data&#34; attribute of the search_TE object.  The maximum length 
        for the indicator is always retrieved. Use slicing to reduce length if needed.

        ** Example: **
        - Run a search and display the &#34;result_table&#34; attribute of the search_TE object to see the search results:

        ```
        search = search_TE()
        search.search_trading_economics(&#34;US ISM Services PMI&#34;)
        search.result_table
        ````

        - Scrape the data for the 11th search result (counts from 0):
        
        ```
        scraped = search.get_data(10)
        scraped.plot_series()  # This will plot an interactive plotly chart of the series.
        ```

        &#34;&#34;&#34;

        print(&#34;Attempting to scrape data for result &#34;, result_num, &#34;, &#34;, self.result_table.loc[result_num, &#34;country&#34;], self.result_table.loc[result_num, &#34;metric&#34;])
        logger.debug(f&#34;Attempting to scrape data for result {result_num}, {self.result_table.loc[result_num, &#39;country&#39;]} {self.result_table.loc[result_num, &#39;metric&#39;]}&#34;)
        if hasattr(self, &#34;result_table&#34;):
            url = self.result_table.loc[result_num, &#34;url&#34;]
            print(f&#34;Scraping data from: {url}&#34;)
            self.scraped_data = scrape_chart(url, driver = self.driver, headless=self.headless, browser=self.browser)
            if self.scraped_data is not None:
                print(f&#34;Data scraped successfully from: {url}&#34;)
                logger.debug(f&#34;Data scraped successfully from: {url}&#34;)
            return self.scraped_data
        else:
            print(&#34;No search result found with the number specified: &#34;, result_num)
            logger.debug(f&#34;No search result found with the number specified: {result_num}&#34;)
            return None</code></pre>
</details>
<div class="desc"><p>Class for searching Trading Economics website and extracting search results.
This class is designed to search the Trading Economics website for a given term and extract the search results.
It can load the search page, enter a search term, and extract the URLs of the search results.</p>
<p><strong>Init Parameters:</strong></p>
<ul>
<li>driver (webdriver): A Selenium WebDriver object, can put in an active one or make a new one for a new URL.</li>
<li>use_existing_driver (bool): Whether to use an existing driver or make a new one.</li>
<li>browser (str): The browser to use for scraping, either 'chrome' or 'firefox'.</li>
<li>search_term (str): The term to search for on the website. Optional, can also provide it in the search_trading_economics method.</li>
<li>headless (bool): Whether to run the browser in headless mode (show no window).</li>
</ul></div>
<h3>Class variables</h3>
<dl>
<dt id="tedata.search.search_TE.BrowserType"><code class="name">var <span class="ident">BrowserType</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tedata.search.search_TE.extract_search_results"><code class="name flex">
<span>def <span class="ident">extract_search_results</span></span>(<span>self, html_content)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_search_results(self, html_content):
    &#34;&#34;&#34;Extract URLs from search results page&#34;&#34;&#34;
    
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
    
    # Find all list items in search results
    results = soup.find_all(&#39;li&#39;, class_=&#39;list-group-item&#39;)
    
    urls = []
    for result in results:
        # Find the main link in each result item
        link = result.find(&#39;a&#39;, href=True)
        if link and link[&#39;href&#39;].startswith(&#39;/&#39;):
            full_url = f&#34;https://tradingeconomics.com{link[&#39;href&#39;]}&#34;
            urls.append(full_url)
    
    return urls</code></pre>
</details>
<div class="desc"><p>Extract URLs from search results page</p></div>
</dd>
<dt id="tedata.search.search_TE.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self, result_num: int = 0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data(self, result_num: int = 0):
    &#34;&#34;&#34;Scrape data for a given search result number.
    This method will scrape data for a given search result number from the search results table.
    It will extract the URL for the result and scrape the data from the chart at that URL.
    The scraped data is assigned to the &#39;scraped_data&#39; attribute as a TE_scraper object.
    This will use the TE_Scraper class and methods to scrape the data from the Trading Economics website.
    
    **Parameters:**
    - result_num (int): The index of the search result in your result table to scrape the data for.

    **Returns:**
    - scraped_data (TE_Scraper): The scraped data object. The data can be accessed from the &#39;series&#39; attribute of the TE_SCraper object
    that is returned. This object is also saved as the &#34;scraped_data&#34; attribute of the search_TE object.  The maximum length 
    for the indicator is always retrieved. Use slicing to reduce length if needed.

    ** Example: **
    - Run a search and display the &#34;result_table&#34; attribute of the search_TE object to see the search results:

    ```
    search = search_TE()
    search.search_trading_economics(&#34;US ISM Services PMI&#34;)
    search.result_table
    ````

    - Scrape the data for the 11th search result (counts from 0):
    
    ```
    scraped = search.get_data(10)
    scraped.plot_series()  # This will plot an interactive plotly chart of the series.
    ```

    &#34;&#34;&#34;

    print(&#34;Attempting to scrape data for result &#34;, result_num, &#34;, &#34;, self.result_table.loc[result_num, &#34;country&#34;], self.result_table.loc[result_num, &#34;metric&#34;])
    logger.debug(f&#34;Attempting to scrape data for result {result_num}, {self.result_table.loc[result_num, &#39;country&#39;]} {self.result_table.loc[result_num, &#39;metric&#39;]}&#34;)
    if hasattr(self, &#34;result_table&#34;):
        url = self.result_table.loc[result_num, &#34;url&#34;]
        print(f&#34;Scraping data from: {url}&#34;)
        self.scraped_data = scrape_chart(url, driver = self.driver, headless=self.headless, browser=self.browser)
        if self.scraped_data is not None:
            print(f&#34;Data scraped successfully from: {url}&#34;)
            logger.debug(f&#34;Data scraped successfully from: {url}&#34;)
        return self.scraped_data
    else:
        print(&#34;No search result found with the number specified: &#34;, result_num)
        logger.debug(f&#34;No search result found with the number specified: {result_num}&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Scrape data for a given search result number.
This method will scrape data for a given search result number from the search results table.
It will extract the URL for the result and scrape the data from the chart at that URL.
The scraped data is assigned to the 'scraped_data' attribute as a TE_scraper object.
This will use the TE_Scraper class and methods to scrape the data from the Trading Economics website.</p>
<p><strong>Parameters:</strong>
- result_num (int): The index of the search result in your result table to scrape the data for.</p>
<p><strong>Returns:</strong>
- scraped_data (TE_Scraper): The scraped data object. The data can be accessed from the 'series' attribute of the TE_SCraper object
that is returned. This object is also saved as the "scraped_data" attribute of the search_TE object.
The maximum length
for the indicator is always retrieved. Use slicing to reduce length if needed.</p>
<p>** Example: **
- Run a search and display the "result_table" attribute of the search_TE object to see the search results:</p>
<pre><code>search = search_TE()
search.search_trading_economics(&quot;US ISM Services PMI&quot;)
search.result_table
````

- Scrape the data for the 11th search result (counts from 0):

</code></pre>
<p>scraped = search.get_data(10)
scraped.plot_series()
# This will plot an interactive plotly chart of the series.
```</p></div>
</dd>
<dt id="tedata.search.search_TE.home_page"><code class="name flex">
<span>def <span class="ident">home_page</span></span>(<span>self, timeout: int = 30)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def home_page(self, timeout: int = 30):
    &#34;&#34;&#34;Load the Trading Economics home page.
    :Parameters:
    - timeout (int): The maximum time to wait for the page to load, in seconds.

    &#34;&#34;&#34;
    # Load page
    try:
        logger.info(&#34;Loading home page at https://tradingeconomics.com/ ...&#34;)
        self.driver.get(&#34;https://tradingeconomics.com/&#34;)

        # Wait for 5 seconds
        time.sleep(5)
        # Check if search box exists
        search_box = self.driver.find_elements(By.ID, &#34;thisIstheSearchBoxIdTag&#34;)
        if search_box:
            logger.info(&#34;Home page at https://tradingeconomics.com loaded successfully! Search box element found.&#34;)
        else:
            logger.info(&#34;Home page at https://tradingeconomics.com loaded successfully! Search box element not found though.&#34;)
        
    except Exception as e:
        logger.info(f&#34;Error occurred, check internet connection. Error details: {str(e)}&#34;)
        logger.debug(f&#34;Error occurred, check internet connection. Error details: {str(e)}&#34;)</code></pre>
</details>
<div class="desc"><p>Load the Trading Economics home page.
:Parameters:
- timeout (int): The maximum time to wait for the page to load, in seconds.</p></div>
</dd>
<dt id="tedata.search.search_TE.results_table"><code class="name flex">
<span>def <span class="ident">results_table</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def results_table(self):
    &#34;&#34;&#34;Create a DataFrame from the search results&#34;&#34;&#34;

    if hasattr(self, &#34;results&#34;):
        metrics = []
        countries = []
        for result in self.results:
            metrics.append(result.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;))
            countries.append(result.split(&#34;/&#34;)[-2].replace(&#34;-&#34;, &#34; &#34;))
        df = pd.DataFrame({&#39;country&#39;: countries, &#39;metric&#39;: metrics, &#34;url&#34;: self.results})
        df.index.rename(&#39;result&#39;, inplace=True)
        self.result_table = df
    else:
        print(&#34;No search results found.&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Create a DataFrame from the search results</p></div>
</dd>
<dt id="tedata.search.search_TE.search_trading_economics"><code class="name flex">
<span>def <span class="ident">search_trading_economics</span></span>(<span>self, search_term: str = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search_trading_economics(self, search_term: str = None):
    &#34;&#34;&#34;Search Trading Economics website for a given term and extract URLs of search results.
    This method will search the Trading Economics website for a given term and extract the URLs of the search results.
    It will enter the search term in the search box, submit the search, and extract the URLs of the search results.
    Results are assigned to the &#39;results&#39; attribute as a list of URLs and as result_table attribute as a pandas df.

    **Parameters:**

    - search_term (str): The term to search for on the website.
    &#34;&#34;&#34;

    self.current_page = self.driver.current_url
    if self.current_page != &#34;https://tradingeconomics.com/&#34;:
        self.home_page()
        time.sleep(2)

    if search_term is None:
        search_term = self.search_term
    else:
        self.search_term = search_term
    logger.debug(f&#34;Searching Trading Economics for: {self.search_term}&#34;)
    
    try:
    # Wait for search box - using the ID from the HTML
        search_box = WebDriverWait(self.driver, 30).until(
            EC.presence_of_element_located((By.ID, &#34;thisIstheSearchBoxIdTag&#34;)))

        # Click search box
        logger.info(&#34;Clicking search box...&#34;)
        search_box.click()
        
        # Enter search term
        logger.info(f&#34;Entering search term: {search_term}&#34;)
        search_box.send_keys(search_term)
        time.sleep(1)  # Small delay to let suggestions appear
        
        # Press Enter
        logger.info(&#34;Submitting search...&#34;)
        search_box.send_keys(Keys.RETURN)
        
        # Wait a moment to see results
        time.sleep(3)

        self.results = self.extract_search_results(self.driver.page_source)
        self.results_table()
        logger.debug(f&#34;Search for {self.search_term} completed successfully.&#34;)
    
    except Exception as e:
        logger.info(f&#34;Error occurred: {str(e)}&#34;)
        logger.debug(f&#34;Error on search occurred: {str(e)}&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Search Trading Economics website for a given term and extract URLs of search results.
This method will search the Trading Economics website for a given term and extract the URLs of the search results.
It will enter the search term in the search box, submit the search, and extract the URLs of the search results.
Results are assigned to the 'results' attribute as a list of URLs and as result_table attribute as a pandas df.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>search_term (str): The term to search for on the website.</li>
</ul></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tedata" href="index.html">tedata</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tedata.search.search_TE" href="#tedata.search.search_TE">search_TE</a></code></h4>
<ul class="">
<li><code><a title="tedata.search.search_TE.BrowserType" href="#tedata.search.search_TE.BrowserType">BrowserType</a></code></li>
<li><code><a title="tedata.search.search_TE.extract_search_results" href="#tedata.search.search_TE.extract_search_results">extract_search_results</a></code></li>
<li><code><a title="tedata.search.search_TE.get_data" href="#tedata.search.search_TE.get_data">get_data</a></code></li>
<li><code><a title="tedata.search.search_TE.home_page" href="#tedata.search.search_TE.home_page">home_page</a></code></li>
<li><code><a title="tedata.search.search_TE.results_table" href="#tedata.search.search_TE.results_table">results_table</a></code></li>
<li><code><a title="tedata.search.search_TE.search_trading_economics" href="#tedata.search.search_TE.search_trading_economics">search_trading_economics</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.5</a>.</p>
</footer>
</body>
</html>
